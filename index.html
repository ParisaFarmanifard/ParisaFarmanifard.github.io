<!DOCTYPE html>
<html>
<head>
    <link href='https://fonts.googleapis.com/css?family=Roboto:400,700&display=swap' rel='stylesheet'>
    <title>Parisa Farmanifard</title>
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <style>
        
        body {
            margin: 0 auto;
            max-width: 960px;
            font-family: 'Roboto', sans-serif;
            background-color: #f4f4f9;
            color: #333;
            line-height: 1.6;
        }
        .header {
            text-align: center;
            padding: 20px;
            border-bottom: 5px solid #00b300; /* Thicker and green border */
        }
        h1, h3 {
            color: #333;
        }
        h1 {
            font-size: 28px;
            text-align: center;
            margin-top: 20px;
        }
        h3 {
            margin-top: 20px;
            font-size: 24px;
            color: #3352FF; /* MSU Blue */
        }
        h4 {
            color: #007BFF; /* Brighter Blue */
            margin-top: 10px;
            font-size: 18px;
        }
        p, li {
            font-size: 16px;
        }
        .title {
            border-bottom: 2px solid darkgreen; /* Dark green underlined title */
            padding-bottom: 10px; /* Padding under the text */
        }
        .profile-picture {
            width: 150px;
            height: 150px;
            border-radius: 50%;
            border: 4px solid #3352FF;
            object-fit: cover;
            margin-right: 20px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .social-links {
            display: flex;
            align-items: center;
            margin-bottom: 20px;
        }
        .social-links a {
            margin: 0 10px;
            display: flex; 
        }
        .social-links img {
            width: 30px;
            height: 30px;
        }
        .section {
            padding-top: 20px;
            border-top: 2px solid #ccc; /* Light gray border for section separation */
        }
        .project {
            padding: 10px;
            background-color: #ffffff;
            box-shadow: 0 4px 8px rgba(0,0,0,0.1);
            margin-top: 10px;
            border-radius: 8px;
        }
        a {
            color: #007BFF;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
        .project p {
            text-align: justify;
    }
        li {
            text-align: justify; /* Justifies the text for better readability */
            margin: 10px; /* Adds some space around each list item */
        }
    </style>
</head>
<body>
    <div class="header">
        <h1 class="title">Parisa Farmanifard</h1>
    </div>
    <hr>
    <div class="intro">
        <img src="images/MSU.jpg" alt="Parisa Farmanifard" class="profile-picture">
        <p style="text-align: justify;"> 

            Welcome to my webpage! My name is Parisa Farmanifard, a PhD student in the Computer Science and Engineering department at <em>Michigan State University</em>. I am fortunate to be advised by <a href="https://iprobe.cse.msu.edu/people.php">Dr. Arun Ross</a> in the <a href="https://iprobe.cse.msu.edu/index.php">iPRoBe Lab</a>.
            I earned my bachelor's degree in IT Engineering in 2017. Before joining MSU as a direct PhD student in 2021, I worked in the industry for 4 years. Alongside my PhD, I also completed my master's degree at MSU. My research focuses on Computer Vision, Biometrics, and Pattern Recognition.
        </p>
    </div>

    <div class="social-links">
        <a href="https://scholar.google.com/citations?user=q6iHSi8AAAAJ&hl=en&authuser=3" target="_blank">
            <img src="images/googlescholar.png" alt="Google Scholar">
        </a>
        <a href="https://github.com/ParisaFarmanifard" target="_blank">
            <img src="images/github_icon.svg" alt="GitHub">
        </a>
        <a href="https://www.linkedin.com/in/parisaf/" target="_blank">
            <img src="images/linkedin_logo_icon.svg" alt="LinkedIn">
        </a>
    </div>
    <div class="section">
    <h3>Publications</h3>
    <p style="text-align: justify;"> 
   [2024] <strong> P. Farmanifard </strong> and A. Ross,<a href="https://arxiv.org/abs/2408.04868"><em>"ChatGPT Meets Iris Biometrics"</em></a> ,Proc. of International Joint Conference on Biometrics (IJCB), (Buffalo, USA), September 2024. </p>
    <p style="text-align: justify;"> 
   [2024] <strong>P. Farmanifard </strong> and A. Ross,<a href="https://arxiv.org/abs/2402.06497"><em>"Iris-SAM: Iris Segmentation Using a Foundation Model"</em></a> ,Proc. of 4th International Conference on Pattern Recognition and Artificial Intelligence (ICPRAI), (Jeju Island, South Korea), July 2024.</p>
   </div>

<div class="section">
    <h3>Projects</h3>
        <div class="project PAD">
        <h4> Iris Presentation Attack Detection (PAD) </h4>
        <p style="text-align: justify;"> 
        Currently, working on improving the detection of contact lenses in iris images to prevent fraud in iris recognition systems. Specifically, I use deep learning models to distinguish between natural irises and those altered by clear or patterned contact lenses, aiming to boost the security of these biometric systems.
        </p>
    </div>
    <div class="project chatgpt-iris-biometrics">
        <h4>ChatGPT Meets Iris Biometrics</h4>
        <p style="text-align: justify;"> 
        This study utilizes the advanced capabilities of the GPT4 multimodal Large Language Model (LLM) to explore its potential in iris recognition — a field less common and more specialized than face recognition. By focusing on this niche yet crucial area, we investigate how well AI tools like ChatGPT can understand and analyze iris images. Through a
        series of meticulously designed experiments employing a zero-shot learning approach, the capabilities of ChatGPT-4 was assessed across various challenging conditions including diverse datasets, presentation attacks, occlusions such as glasses, and other real-world variations. The findings
        convey ChatGPT-4’s remarkable adaptability and precision, revealing its proficiency in identifying distinctive iris features, while also detecting subtle effects like makeup on iris recognition. A comparative analysis with Gemini Advanced – Google’s AI model – highlighted ChatGPT-4’s
        better performance and user experience in complex iris analysis tasks. This research not only validates the use of LLMs for specialized biometric applications but also emphasizes the importance of nuanced query framing and interaction design in extracting significant insights from biometric data.
        Our findings suggest a promising path for future research and the development of more adaptable, efficient, robust and interactive biometric security solutions.
        </p>
    </div>
    <div class="project iris-sam-segmentation">
        <h4>Iris-SAM: Iris Segmentation Using a Foundation Model</h4>
        <p style="text-align: justify;"> 
        Iris segmentation is a critical component of an iris biometric system and it involves extracting the annular iris region from an ocular image. In this work, we develop a pixel-level iris segmentation model from a foundation model, viz., Segment Anything Model (SAM), that
        has been successfully used for segmenting arbitrary objects. The primary contribution of this work lies in the integration of different loss functions during the fine-tuning of SAM on ocular images. In particular, the importance of Focal Loss is borne out in the fine-tuning process since it
        strategically addresses the class imbalance problem (i.e., iris versus noniris pixels). Experiments on ND-IRIS-0405, CASIA-Iris-Interval-v3, and IIT-Delhi-Iris datasets convey the efficacy of the trained model for the task of iris segmentation. For instance, on the ND-IRIS-0405 dataset, an
        average segmentation accuracy of 99.58% was achieved, compared to the best baseline performance of 89.75%.
        </p>
        <a href="https://github.com/ParisaFarmanifard/Iris-SAM" target="_blank">View on GitHub</a>

    </div>
    <div class="project gans">
        <h4> Cross-Spectral Face Recognition Using Generative Adversarial Networks (GANs)</h4>
        <p style="text-align: justify;"> 
        Cross-spectral Face Recognition (CFR) refers to the task of identifying matching features between two images of the same person captured in two different spectral bands. This involves recognizing faces across different imaging modalities such as visible, infrared, or depth maps. In this study, 
        we used ArcFace to calculate match scores between images taken from different spectral bands. We first computed similarity scores between original images of the same identity captured in SWIR and VIS, and then compared them with similarities between synthesized VIS images and the 
        original VIS/SWIR images using SG-GAN. Our results showed that using ArcFace led to the best performance for both synthesized and original images. This was because the similarity scores were well-separated in the histogram, indicating high discrimination between different identities. However, the performance of outdoor image analysis can be improved by applying image enhancement methods that address issues such as low contrast, noise, or illumination variations.</p>
    </div>
</div>

    <div class="section">
        <h3>Poster Presentations</h3>
        <ul>
            <li>"ChatGPT Meets Iris Biometrics", IJCB 2024 (Buffalo, NY).</li>
            <li>"Iris-SAM: Iris Segmentation Using a Foundation Model", Engineering Graduate Research Symposium 2024 (MSU).</li>
            <li>"Cross-Spectral Face Recognition Using a Semantic-Guided GAN", Engineering Graduate Research Symposium 2023 (MSU).</li>
        </ul>
    </div>
    <div class="section">
        <h3>Education</h3>
        <ul>
            <li> [2021 - Present], Doctors of Philosophy (Ph.D.), Computer Science, Michigan State University, USA.</li>
            <li> [2021 - 2023], Master of Science (MS), Computer Science, Michigan State University, USA.</li>
            <li> [2013 - 2017], Bachelors of Engineering (B.E.), IT Engineering, Iran.</li>
        </ul>
    </div>
    <div class="section">
        <h3>Internship Experience</h3>
        <ul>
            <li>In the summer of 2023, I had an internship experience at <a href="https://www.aep.com/">American Electric Power (AEP)</a>, working with their emerging technology group. My role involved a project on <em>"drone-based pole detection"</em>, collaborating closely with a computer vision and machine learning group. During my internship, I have worked with various detection methods, including <strong>Detectron2, Yolov4, Yolov8</strong>, and the <strong>Segment Anything Model (SAM)</strong>, primarily focusing on drone images.</li>
        </ul>
    </div>

    <br>
</body>
</html>
